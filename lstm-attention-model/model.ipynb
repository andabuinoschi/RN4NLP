{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abuinoschi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abuinoschi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "  \n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../dataset/train.tsv', sep='\\t')\n",
    "train_data = train_data.fillna('unknown')\n",
    "\n",
    "validation_data = pd.read_csv('../dataset/test.tsv', sep='\\t')\n",
    "validation_data = validation_data.fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    4428\n",
       "no     1977\n",
       "Name: q1_label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['q1_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no         3902\n",
       "unknown    2024\n",
       "yes         479\n",
       "Name: q2_label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['q2_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes        4315\n",
       "unknown    1962\n",
       "no          128\n",
       "Name: q3_label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['q3_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no         3745\n",
       "unknown    1972\n",
       "yes         688\n",
       "Name: q4_label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['q4_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "train_data = pd.get_dummies(train_data, columns=['q2_label', 'q3_label', 'q4_label'], prefix=[\"q2_label_is\", \"q3_label_is\", \"q4_label_is\"] )\n",
    "\n",
    "# One hot encoding\n",
    "validation_data = pd.get_dummies(validation_data, columns=['q2_label', 'q3_label', 'q4_label'], prefix=[\"q2_label_is\", \"q3_label_is\", \"q4_label_is\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_no</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>q1_label</th>\n",
       "      <th>q5_label</th>\n",
       "      <th>q6_label</th>\n",
       "      <th>q7_label</th>\n",
       "      <th>language</th>\n",
       "      <th>tweet_link</th>\n",
       "      <th>tweet_link_count</th>\n",
       "      <th>preprocessed_tweet_text</th>\n",
       "      <th>...</th>\n",
       "      <th>preprocessed_tweet_text_no_link</th>\n",
       "      <th>q2_label_is_no</th>\n",
       "      <th>q2_label_is_unknown</th>\n",
       "      <th>q2_label_is_yes</th>\n",
       "      <th>q3_label_is_no</th>\n",
       "      <th>q3_label_is_unknown</th>\n",
       "      <th>q3_label_is_yes</th>\n",
       "      <th>q4_label_is_no</th>\n",
       "      <th>q4_label_is_unknown</th>\n",
       "      <th>q4_label_is_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>For the average American the best way to tell ...</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>For the average American the best way to tell ...</td>\n",
       "      <td>...</td>\n",
       "      <td>For the average American the best way to tell ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>this is fucking bullshit</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>this is fucking bullshit</td>\n",
       "      <td>...</td>\n",
       "      <td>this is fucking bullshit</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_no                                         tweet_text q1_label  \\\n",
       "0         1  For the average American the best way to tell ...       no   \n",
       "1         2                           this is fucking bullshit       no   \n",
       "\n",
       "  q5_label q6_label q7_label language tweet_link  tweet_link_count  \\\n",
       "0  unknown       no       no       en         []                 0   \n",
       "1  unknown       no       no       en         []                 0   \n",
       "\n",
       "                             preprocessed_tweet_text  ...  \\\n",
       "0  For the average American the best way to tell ...  ...   \n",
       "1                           this is fucking bullshit  ...   \n",
       "\n",
       "                     preprocessed_tweet_text_no_link q2_label_is_no  \\\n",
       "0  For the average American the best way to tell ...              0   \n",
       "1                           this is fucking bullshit              0   \n",
       "\n",
       "  q2_label_is_unknown q2_label_is_yes q3_label_is_no  q3_label_is_unknown  \\\n",
       "0                   1               0              0                    1   \n",
       "1                   1               0              0                    1   \n",
       "\n",
       "   q3_label_is_yes  q4_label_is_no  q4_label_is_unknown  q4_label_is_yes  \n",
       "0                0               0                    1                0  \n",
       "1                0               0                    1                0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[['preprocessed_tweet_text', 'q1_label', \n",
    "                         'q2_label_is_no', 'q2_label_is_unknown', 'q2_label_is_yes', \n",
    "                         'q3_label_is_no', 'q3_label_is_unknown', 'q3_label_is_yes', \n",
    "                         'q4_label_is_no', 'q4_label_is_unknown', 'q4_label_is_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = validation_data[['preprocessed_tweet_text', 'q1_label', \n",
    "                         'q2_label_is_no', 'q2_label_is_unknown', 'q2_label_is_yes', \n",
    "                         'q3_label_is_no', 'q3_label_is_unknown', 'q3_label_is_yes', \n",
    "                         'q4_label_is_no', 'q4_label_is_unknown', 'q4_label_is_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_tweet_text</th>\n",
       "      <th>q1_label</th>\n",
       "      <th>q2_label_is_no</th>\n",
       "      <th>q2_label_is_unknown</th>\n",
       "      <th>q2_label_is_yes</th>\n",
       "      <th>q3_label_is_no</th>\n",
       "      <th>q3_label_is_unknown</th>\n",
       "      <th>q3_label_is_yes</th>\n",
       "      <th>q4_label_is_no</th>\n",
       "      <th>q4_label_is_unknown</th>\n",
       "      <th>q4_label_is_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>average american best way tell covid19 cough r...</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck bullshit</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yall please follow government instruction knoc...</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offense corona virus disappear april actually ...</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>face someone spend 9 hour personal protective ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             preprocessed_tweet_text q1_label  q2_label_is_no  \\\n",
       "0  average american best way tell covid19 cough r...       no               0   \n",
       "1                                      fuck bullshit       no               0   \n",
       "2  yall please follow government instruction knoc...       no               0   \n",
       "3  offense corona virus disappear april actually ...       no               0   \n",
       "4  face someone spend 9 hour personal protective ...      yes               1   \n",
       "\n",
       "   q2_label_is_unknown  q2_label_is_yes  q3_label_is_no  q3_label_is_unknown  \\\n",
       "0                    1                0               0                    1   \n",
       "1                    1                0               0                    1   \n",
       "2                    1                0               0                    1   \n",
       "3                    1                0               0                    1   \n",
       "4                    0                0               0                    0   \n",
       "\n",
       "   q3_label_is_yes  q4_label_is_no  q4_label_is_unknown  q4_label_is_yes  \n",
       "0                0               0                    1                0  \n",
       "1                0               0                    1                0  \n",
       "2                0               0                    1                0  \n",
       "3                0               0                    1                0  \n",
       "4                1               1                    0                0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "  \n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
    "    text = text.lower()\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "    text = [word for word in text if  not word in stop_words]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "training_data = train_data\n",
    "training_data['preprocessed_tweet_text'] = training_data.preprocessed_tweet_text.apply(lambda x: clean_text(x))\n",
    "validation_data['preprocessed_tweet_text'] = validation_data.preprocessed_tweet_text.apply(lambda x: clean_text(x))\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    4428\n",
       "no     1977\n",
       "Name: q1_label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['q1_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['q1_label'] = training_data['q1_label'].map({'no': 0, 'yes':1})\n",
    "validation_data['q1_label'] = validation_data['q1_label'].map({'no': 0, 'yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 128\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(training_data['preprocessed_tweet_text'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(training_data['preprocessed_tweet_text'])\n",
    "list_tokenized_valid = tokenizer.texts_to_sequences(validation_data['preprocessed_tweet_text'])\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(list_tokenized_train, maxlen=MAX_LEN)\n",
    "y_train = train_data['q1_label']\n",
    "\n",
    "X_validation = tf.keras.preprocessing.sequence.pad_sequences(list_tokenized_valid, maxlen=MAX_LEN)\n",
    "y_validation = validation_data['q1_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model (LSTM + Attention layer) for Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "          \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = tf.nn.tanh(\n",
    "            self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "          \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = tf.keras.layers.Input(shape=(128,), dtype=\"int32\")\n",
    "embedding = tf.keras.layers.Embedding(VOCAB_SIZE, 128)(sequence_input)\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences = True), name=\"bi_lstm_0\")(embedding)\n",
    "(lstm, forward_h, forward_c, backward_h, backward_c) = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True, return_state=True), name=\"bi_lstm_1\")(lstm)\n",
    "state_h  = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
    "state_c =  tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
    "context_vector, attention_weights = Attention(32)(lstm, state_h)\n",
    "dense1 = tf.keras.layers.Dense(16, activation=\"relu\")(context_vector)\n",
    "dropout = tf.keras.layers.Dropout(0.1)(dense1)\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dropout)\n",
    "model = tf.keras.Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "          optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 128, 128)     1280000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " bi_lstm_0 (Bidirectional)      (None, 128, 256)     263168      ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " bi_lstm_1 (Bidirectional)      [(None, 128, 128),   164352      ['bi_lstm_0[0][0]']              \n",
      "                                 (None, 64),                                                      \n",
      "                                 (None, 64),                                                      \n",
      "                                 (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128)          0           ['bi_lstm_1[0][1]',              \n",
      "                                                                  'bi_lstm_1[0][3]']              \n",
      "                                                                                                  \n",
      " attention (Attention)          ((None, 128),        8289        ['bi_lstm_1[0][0]',              \n",
      "                                 (None, 128, 1))                  'concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 16)           2064        ['attention[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 16)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            17          ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,717,890\n",
      "Trainable params: 1,717,890\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "51/51 [==============================] - 52s 916ms/step - loss: 0.6438 - accuracy: 0.6842 - val_loss: 0.7552 - val_accuracy: 0.5335\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 47s 928ms/step - loss: 0.6221 - accuracy: 0.6913 - val_loss: 0.7402 - val_accuracy: 0.5335\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 49s 963ms/step - loss: 0.6198 - accuracy: 0.6913 - val_loss: 0.7594 - val_accuracy: 0.5335\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 50s 984ms/step - loss: 0.6207 - accuracy: 0.6913 - val_loss: 0.7427 - val_accuracy: 0.5335\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 50s 978ms/step - loss: 0.6163 - accuracy: 0.6913 - val_loss: 0.7408 - val_accuracy: 0.5335\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 51s 1s/step - loss: 0.5992 - accuracy: 0.6913 - val_loss: 0.7001 - val_accuracy: 0.5335\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 53s 1s/step - loss: 0.4636 - accuracy: 0.7700 - val_loss: 0.7610 - val_accuracy: 0.6890\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 54s 1s/step - loss: 0.3689 - accuracy: 0.8515 - val_loss: 0.5971 - val_accuracy: 0.7352\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 53s 1s/step - loss: 0.3174 - accuracy: 0.8792 - val_loss: 0.6402 - val_accuracy: 0.7132\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 54s 1s/step - loss: 0.2789 - accuracy: 0.8998 - val_loss: 0.6756 - val_accuracy: 0.7403\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['predicted_q1'] = predictions\n",
    "validation_data['predicted_q1'] = validation_data.apply(lambda row: 0 if row['predicted_q1'] < 0.5 else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted no</th>\n",
       "      <th>Predicted yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual no</th>\n",
       "      <td>548</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual yes</th>\n",
       "      <td>181</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted no  Predicted yes\n",
       "Actual no            548            280\n",
       "Actual yes           181            766"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(validation_data['q1_label'], validation_data['predicted_q1'])\n",
    "pd.DataFrame(cm, index=['Actual no', 'Actual yes'], columns = ['Predicted no', 'Predicted yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
